# The Conversation

In late 2024, multiple teams working independently reported a shift in agentic coding workflows: models appeared to compound correctness rather than error. Three intellectual lineages converged on a shared formula — **Seed → Validation → Feedback Loop**, fueled by tokens — raising questions about what it means, what infrastructure it requires, what remains unproven, and how the broader community is responding.

For the full framing, see the [meta overview](README.md). For specific threads: [the moment and the formula](meta.md), [the three lineages](paradigm.md), [the hard questions](questions.md), [the readiness model](maturity-model.md).

Community commentary, counterarguments, and experience reports:

- [Simon Willison's review thread on X](https://x.com/simonw/status/2020161285376082326) — Willison's commentary and community responses
- [The Hacker News discussion](https://news.ycombinator.com/item?id=46924426#46931812) — Perspectives, counterarguments, and experience reports
- [Greg Brockman on retooling for agentic development](https://x.com/gdb/status/2019566641491963946) — OpenAI's internal approach: agents captains, AGENTS.md, agent-first codebases, quality standards, and infrastructure priorities
- [Aaron Levie on structuring work agent-first](https://x.com/levie/status/2019634114874470819) — The implicit context gap between humans and agents, documentation as competitive advantage, agentic coding as leading indicator for all knowledge work
