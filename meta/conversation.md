# The Conversation

In late 2024, multiple teams working independently reported a shift in agentic coding workflows: models appeared to compound correctness rather than error. Three intellectual lineages converged on a shared formula — **Seed → Validation → Feedback Loop**, fueled by tokens — raising questions about what it means, what infrastructure it requires, what remains unproven, and how the broader community is responding.

For the full framing, see the [meta overview](README.md). For specific threads:

- **[The moment and the formula](meta.md)** — the convergence and the shared insight
- **[Three lineages](paradigm.md)** — compound engineering, agent-native development, and the software factory vision
- **[Honest questions](questions.md)** — provability, token economics, and what readiness really means
- **[Agent Readiness Model](maturity-model.md)** — five maturity levels, nine technical pillars

Community commentary, counterarguments, and experience reports:

- [Simon Willison's review thread on X](https://x.com/simonw/status/2020161285376082326) — Willison's commentary and community responses
- [The Hacker News discussion](https://news.ycombinator.com/item?id=46924426#46931812) — Perspectives, counterarguments, and experience reports
- [Greg Brockman on retooling for agentic development](https://x.com/gdb/status/2019566641491963946) — OpenAI's internal approach: agents captains, AGENTS.md, agent-first codebases, quality standards, and infrastructure priorities
- [Aaron Levie on structuring work agent-first](https://x.com/levie/status/2019634114874470819) — The implicit context gap between humans and agents, documentation as competitive advantage, agentic coding as leading indicator for all knowledge work
