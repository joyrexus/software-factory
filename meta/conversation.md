# The Conversation

In late 2024, multiple teams working independently reported a shift in agentic coding workflows: models appeared to compound correctness rather than error. Three intellectual lineages converged on a shared formula — **Seed → Validation → Feedback Loop**, fueled by tokens — raising questions about what it means, what infrastructure it requires, what remains unproven, and how the broader community is responding.

For the full framing, see the [meta overview](README.md). For specific threads:

- **[The moment and the formula](meta.md)** — the convergence and the shared insight
- **[Three lineages](paradigm.md)** — compound engineering, agent-native development, and the software factory vision
- **[Honest questions](questions.md)** — provability, token economics, and what readiness really means
- **[Agent Readiness Model](maturity-model.md)** — five maturity levels, nine technical pillars

Community commentary, counterarguments, and experience reports:

- [Simon Willison's review thread](../SOURCES.md#simon-willisons-review) — Willison's commentary and community responses
- [The Hacker News discussion](../SOURCES.md#simon-willisons-review) — Perspectives, counterarguments, and experience reports
- [Retooling for agentic development](../SOURCES.md#retooling-for-agentic-development) (Brockman) — OpenAI's internal approach: agents captains, AGENTS.md, agent-first codebases, quality standards, and infrastructure priorities
- [Structuring work agent-first](../SOURCES.md#structuring-work-agent-first) (Levie) — The implicit context gap between humans and agents, documentation as competitive advantage, agentic coding as leading indicator for all knowledge work
